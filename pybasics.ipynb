{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version: 3.10.6\n",
      "pandas: 1.4.3\n",
      "numpy:  1.23.2\n",
      "cufflinks:  0.17.3\n",
      "seaborn:  0.11.2\n",
      "matplotlib:  3.5.3\n",
      "Current Path:  c:\\Users\\lsedm\\OneDrive\\001 - Projects\\Python\n"
     ]
    }
   ],
   "source": [
    "# Crtl + Shift + S = Save As\n",
    "from platform import python_version\n",
    "print('python version:' , python_version())\n",
    "import pandas as pd\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "import numpy as np\n",
    "print('numpy: ', np.__version__)\n",
    "import plotly\n",
    "import chart_studio.plotly as py\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import cufflinks as cf\n",
    "print('cufflinks: ', cf.__version__)\n",
    "import seaborn as sns\n",
    "print('seaborn: ', sns.__version__)\n",
    "import matplotlib\n",
    "print('matplotlib: ', matplotlib.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "import re\n",
    "import pandas_profiling\n",
    "import os\n",
    "%matplotlib inline\n",
    "print('Current Path: ',os.getcwd())\n",
    "userpath = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userpath = input()\n",
    "os.chdir(userpath)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Getting data and info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('filepath.extension', sheet_name='sheetname', header=True/False)\n",
    "\n",
    "#display data for validation\n",
    "data.head()\n",
    "\n",
    "#display data type\n",
    "data.dtypes\n",
    "\n",
    "#display the shape of the data [rows, columns]\n",
    "data.shape\n",
    "\n",
    "# get info if the shape isn't too big\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display data profile\n",
    "pandas_profiling.ProfileReport(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Getting column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columns in data:\n",
    "    #display(columns)\n",
    "    #print(columns)\n",
    "#same as\n",
    "list(data.columns)\n",
    "#same as\n",
    "list(data.columns.values)\n",
    "#same as\n",
    "list(data.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Renaming column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename specific columns\n",
    "data.rename(columns = {'old_col1':'new_col1', 'old_col2':'new_col2'}, inplace = True)\n",
    "\n",
    "#rename all columns\n",
    "data.columns = ['new_col1', 'new_col2', 'new_col3', 'new_col4']\n",
    "\n",
    "#rename specific character in columns\n",
    "data.columns = data.columns.str.replace('old_char', 'new_char')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Add or Drop column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column\n",
    "data['newcol'] = 1 \n",
    "\n",
    "#drop column \n",
    "data = data.drop([\n",
    "    'col1',\n",
    "    'col2',\n",
    "    ], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Append multiple files together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all files in location and the append them together\n",
    "\n",
    "input_loc = 'filepath'\n",
    "output_loc = 'filepath'\n",
    "\n",
    "fileList = os.listdir(input_loc)\n",
    "fileList\n",
    "\n",
    "finalDf = pd.DataFrame()\n",
    "\n",
    "for files in fileList\n",
    "    if files.endswith('.xlsx'):\n",
    "        df = pd.read_excel(input_loc+files)\n",
    "        finalDf = finalDf.append(df)\n",
    "\n",
    "finalDF.to_excel(output_loc+'filename.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <center><justified> <i> Regular Expressions (RegEx) </i> </b>\n",
    "\n",
    "\n",
    "<i>Character classes</i>\n",
    "\n",
    "\n",
    "    . any character except newline\n",
    "    \\w\\d\\s\tword, digit, whitespace\n",
    "    \\W\\D\\S\tnot word, digit, whitespace\n",
    "    [abc]\tany of a, b, or c\n",
    "    [^abc]\tnot a, b, or c\n",
    "    [a-g]\tcharacter between a & g\n",
    "\n",
    "\n",
    "<i> Anchors</i>\n",
    "\n",
    "    ^abc$\tstart / end of the string\n",
    "    \\b\\B\tword, not-word boundary\n",
    "\n",
    "<i> Escaped characters</i>\n",
    "\n",
    "    \\.\\*\\\\\tescaped special characters\n",
    "    \\t\\n\\r\ttab, linefeed, carriage return\n",
    "\n",
    "<i>Groups & Lookaround</i>\n",
    "\n",
    "    (abc)\tcapture group\n",
    "    \\1\tbackreference to group #1\n",
    "    (?:abc)\tnon-capturing group\n",
    "    (?=abc)\tpositive lookahead\n",
    "    (?!abc)\tnegative lookahead\n",
    "\n",
    "<i>Quantifiers & Alternation</i>\n",
    "\n",
    "    a*a+a?\t0 or more, 1 or more, 0 or 1\n",
    "    a{5}a{2,}\texactly five, two or more\n",
    "    a{1,3}\tbetween one & three\n",
    "    a+?a{2,}?\tmatch as few as possible\n",
    "    ab|cd\tmatch ab or cd\n",
    "\n",
    "<left><i> for help visit: </i>https://regexr.com/\n",
    "\n",
    "<i>or</i> \n",
    "https://www.regular-expressions.info/refcharacters.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Tranforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# varaible as numeric\n",
    "\n",
    "data.<column_name> = data.<column_name>.str.replace(r'\\D','')\n",
    "data.<column_name> = pd.to_numeric(data.<column_name>, errors='coerce').fillna(0)\n",
    "\n",
    "#example\n",
    "data.jailtime = data.jailtime.str.replace(r'\\D','')\n",
    "data.jailtime = pd.to_numeric(data.jailtime, errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wide to long\n",
    "#pandas.melt()\n",
    "pd.melt(frame=data, id_vars=<what are the columns you don't want to touch>, value_vars=<opposite of id_vars>, var_name=<new name>)\n",
    "        \n",
    "        \"\"\"example\n",
    "        data.melt(\n",
    "            data,\n",
    "            id_vars = ['col1', 'col2', 'coln']\n",
    "            var_name = 'horseID'\n",
    "            value_name = 'rating'\n",
    "        )\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Group data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.groupby(['col1', 'col2']).mean()\n",
    "\n",
    "#example\n",
    "mixed_disposition_index = df.groupby(['case', 'guilt'])['jailtime'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Select data by the datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes(include='number').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Replace data for given condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['col'].isin([val,val,val]), 'other col'] = 0\n",
    "\n",
    "#examples: \n",
    "df.loc[df['dispositionid'].isin([172,173,174]), 'guilty'] = 0 #changes col value to 0 if dispoid = 172, 173, or 174\n",
    "data.loc[data['dispo'].isin([167,168,169,170,173]), 'waiver'] = 'Waiver' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe1 = pd.merge(dataframe2, dataframe1, how='left', left_on=['colname'], right_on=['colname'])\n",
    "\n",
    "#example\n",
    "data = pd.merge(data, chargecount, how='right', on = ['case'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Find data for a condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['colname']==value]\n",
    "data.loc[(data['colname'] == value) & (data['colname'] == value)]\n",
    "\n",
    "\n",
    "data = data.loc[(data['colname'] == value) | \n",
    "                (data['colname'] == value) | \n",
    "                (data['colname'] == value)] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Write to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write Results to xlsx\n",
    "writer = pd.ExcelWriter('Filename.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Write each dataframe to a different worksheet. you could write different string like above if you want\n",
    "data.to_excel(writer, sheet_name='Sheet1')\n",
    "\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Panda Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ReportName = ProfileReport(data, \n",
    "                                title='titlename' , \n",
    "                                dataset={\n",
    "                                    'description': 'custome text.',\n",
    "                                    'url': 'https://opd.ohio.gov/',\n",
    "                                    \n",
    "                                },\n",
    "                                variables={\n",
    "                                    'descriptions': {\n",
    "                                        'Guilt': '0=not guilty, 1=guilty',\n",
    "                                        \n",
    "                                    }\n",
    "                                },\n",
    "                                explorative=True,\n",
    "                                )\n",
    "                                \n",
    "ReportName.config.html.style.primary_color ='#33b745'\n",
    "ReportName.to_file(output_file='FileName.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helpful links:\n",
    "\n",
    "Cleaning and tidying datasets: https://www.youtube.com/watch?v=iYie42M1ZyU   9/12 note: 42:00\n",
    "\n",
    "https://www.youtube.com/watch?v=tWFQqaRtSQA\n",
    "\n",
    "https://www.youtube.com/watch?v=RlIiVeig3hc\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd6c2e3f16495d0a5f7b003b72d81e686c37f530e650ed8d2e000e71b5604bf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
